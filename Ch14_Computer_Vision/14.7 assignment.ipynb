{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15210220",
   "metadata": {},
   "source": [
    "# Single Shot Multibox Detection(SSD)\n",
    "배웠던 것을 활용하여 object detection model SSD를 만들어보자.  \n",
    "SSD는 널리 이용되고 있으며 다른 object detection model에도 적용 가능하다.  \n",
    "읽어볼 것 : :cite:`Liu.Anguelov.Erhan.ea.2016`\n",
    "\n",
    "### Model\n",
    "SSD 모델의 주 요소는 base network와 연속적으로 연결된 다규모의 feature block이다.  \n",
    "Base network 블록은 원본 이미지의 feature를 추출하는 데 사용되고 deep convolutional neural network의 형태를 갖는다(그러나 최근 ResNet으로 대체되는 추세다?).\n",
    "\n",
    "### Category Prediction Layer\n",
    "Object category 개수가 $q$면 anchor box category 개수는 $q+1$이 된다. Background만을 포함하는 anchor box의 number는 0이 되는 것이다. Classifying에 FCN을 사용하게 되면 computational burden이 너무 커서 SSD는 model complexity를 감소시킬 필요가 있다.\n",
    "\n",
    "Category prediction layer에서는 input의 h, w를 유지하는 convolutional layer를 사용한다. 즉 output과 input의 좌표는 feature map의 그것과 일대일 대응한다.\n",
    "$a$와 $q$ parameter를 명시한 후에 padding 1, 3 by 3 convolutional layer를 사용한다. Input과 output의 해상도는 변하지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "436f2d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "import d2l\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "def cls_predictor(input_channels, num_anchors, num_classes):\n",
    "    return nn.Conv2d(in_channels=input_channels, out_channels=num_anchors * (num_classes + 1), kernel_size = 3, padding = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64162df7",
   "metadata": {},
   "source": [
    "### Bounding Box Prediction Layer\n",
    "Bounding box prediction layer 설계는 category prediction layer의 그것과 유사하다. 차이점은 anchor box 당 $q+1$이 아닌 4개의 offset이 필요하다는 점이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aee87527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_predictor(input_channels, num_anchors):\n",
    "    return nn.Conv2d(in_channels=input_channels, out_channels=num_anchors * 4, kernel_size = 3, padding = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c088e614",
   "metadata": {},
   "source": [
    "### Concatenating Predictions for Multiple Scales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7fe09d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 55, 20, 20]), torch.Size([2, 33, 10, 10]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def forward(x, block):\n",
    "    return block(x)\n",
    "Y1 = forward(torch.zeros((2, 8, 20, 20)), cls_predictor(8, 5, 10))\n",
    "Y2 = forward(torch.zeros((2, 16, 10, 10)), cls_predictor(16, 3, 10))\n",
    "(Y1.shape, Y2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c49f456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_pred(pred):\n",
    "    return pred.permute(0, 2, 3, 1).reshape(pred.size(0), -1)\n",
    "\n",
    "def concat_preds(preds):\n",
    "    return torch.cat(tuple([flatten_pred(p) for p in preds]), dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3974175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 25300])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_preds([Y1, Y2]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eca80b6",
   "metadata": {},
   "source": [
    "### Height and Width Downsample Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f798ed50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_sample_blk(input_channels, num_channels):\n",
    "    blk = []\n",
    "    for _ in range(2):\n",
    "        blk.append(nn.Conv2d(in_channels = input_channels, out_channels = num_channels, kernel_size = 3, padding = 1))\n",
    "        blk.append(nn.BatchNorm2d(num_features = num_channels))\n",
    "        blk.append(nn.ReLU())\n",
    "        input_channels = num_channels\n",
    "    blk.append(nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "    blk = nn.Sequential(*blk)\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "94845544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 10, 10])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward(torch.zeros((2, 3, 20, 20)), down_sample_blk(3, 10)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba90748",
   "metadata": {},
   "source": [
    "### Base Network Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a66ce5f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 64, 32, 32])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def base_net():\n",
    "    blk = []\n",
    "    num_filters = [3, 16, 32, 64]\n",
    "    for i in range(len(num_filters) - 1):\n",
    "        blk.append(down_sample_blk(num_filters[i], num_filters[i + 1]))\n",
    "    blk = nn.Sequential(*blk)\n",
    "    return blk\n",
    "\n",
    "forward(torch.zeros((2, 3, 256, 256)), base_net()).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f668a5",
   "metadata": {},
   "source": [
    "### The Complete Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ccb09593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blk(i):\n",
    "    if i == 0:\n",
    "        blk = base_net()\n",
    "    elif i == 1:\n",
    "        blk = down_sample_blk(64, 128)\n",
    "    elif i == 4:\n",
    "        blk = nn.AdaptiveMaxPool2d((1, 1))\n",
    "    else:\n",
    "        blk = down_sample_blk(128, 128)\n",
    "        \n",
    "    return blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "42c9bd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import math\n",
    "def create_anchors(feature_map_sizes, steps, sizes):\n",
    "    scale = 256.\n",
    "    steps = [s / scale for s in steps]\n",
    "    sizes = [s / scale for s in sizes]\n",
    "    \n",
    "    aspect_ratios = ((2,),)\n",
    "    \n",
    "    \n",
    "    num_layers = len(feature_map_sizes)\n",
    "    \n",
    "    boxes = []\n",
    "    for i in range(num_layers):\n",
    "        fmsize = feature_map_sizes[i]\n",
    "        for h, w in itertools.product(range(fmsize), repeat = 2):\n",
    "            cx = (w + 0.5) * steps[i]\n",
    "            cy = (h + 0.5) * steps[i]\n",
    "            s = sizes[i]\n",
    "            boxes.append((cx, cy, s, s))\n",
    "            \n",
    "            s = sizes[i + 1]\n",
    "            boxes.append((cx, cy, s, s))\n",
    "            \n",
    "            s = sizes[i]\n",
    "            for ar in aspect_ratios[i]:\n",
    "                boxes.append((cx, cy, (s * math.sqrt(ar)), (s / math.sqrt(ar))))\n",
    "                boxes.append((cx, cy, (s / math.sqrt(ar)), (s * math.sqrt(ar))))\n",
    "                \n",
    "    return torch.Tensor(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "07bd6878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blk_forward(X, blk, size, ratio, cls_predictor, bbox_predictor):\n",
    "    Y = blk(X)\n",
    "    anchors = create_anchors((Y.size(2),), (256 / Y.size(2),), size)\n",
    "    cls_preds = cls_predictor(Y)\n",
    "    bbox_preds = bbox_predictor(Y)\n",
    "    return (Y, anchors, cls_preds, bbox_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "74182378",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [[0.2 * 256, 0.272 * 256], [0.37*256, 0.446 * 256], [0.54 * 256, 0.619 * 256], [0.71 * 256, 0.79 * 256], [0.88 * 256, 0.961 * 256]]\n",
    "ratios = [[1, 2, 0.5]] * 5\n",
    "num_anchors = len(sizes[0]) + len(ratios[0]) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "856029c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinySSD(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(TinySSD, self).__init__()\n",
    "        \n",
    "        input_channels_cls = 128\n",
    "        input_channels_bbox = 128\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.blk = []\n",
    "        self.cls = []\n",
    "        self.bbox = []\n",
    "        \n",
    "        self.blk_0 = get_blk(0)\n",
    "        self.blk_1 = get_blk(1)\n",
    "        self.blk_2 = get_blk(2)\n",
    "        self.blk_3 = get_blk(3)\n",
    "        self.blk_4 = get_blk(4)\n",
    "        \n",
    "        self.cls_0 = cls_predictor(64, num_anchors, num_classes)\n",
    "        self.cls_1 = cls_predictor(input_channels_cls, num_anchors, num_classes)\n",
    "        self.cls_2 = cls_predictor(input_channels_cls, num_anchors, num_classes)\n",
    "        self.cls_3 = cls_predictor(input_channels_cls, num_anchors, num_classes)\n",
    "        self.cls_4 = cls_predictor(input_channels_cls, num_anchors, num_classes)\n",
    "        \n",
    "        self.bbox_0 = bbox_predictor(64, num_anchors)\n",
    "        self.bbox_1 = bbox_predictor(input_channels_bbox, num_anchors)\n",
    "        self.bbox_2 = bbox_predictor(input_channels_bbox, num_anchors)\n",
    "        self.bbox_3 = bbox_predictor(input_channels_bbox, num_anchors)\n",
    "        self.bbox_4 = bbox_predictor(input_channels_bbox, num_anchors)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        anchors, cls_preds, bbox_preds = [None] * 5, [None] * 5, [None] * 5\n",
    "        \n",
    "        X, anchors[0], cls_preds[0], bbox_preds[0] = blk_forward(X, self.blk_0, sizes[0], ratios[0], self.cls_0, self.bbox_0)\n",
    "        \n",
    "        X, anchors[1], cls_preds[1], bbox_preds[1] = blk_forward(X, self.blk_1, sizes[1], ratios[1], self.cls_1, self.bbox_1)\n",
    "            \n",
    "        X, anchors[2], cls_preds[2], bbox_preds[2] = blk_forward(X, self.blk_2, sizes[2], ratios[2], self.cls_2, self.bbox_2)    \n",
    "        \n",
    "        X, anchors[3], cls_preds[3], bbox_preds[3] = blk_forward(X, self.blk_3, sizes[3], ratios[3], self.cls_3, self.bbox_3)\n",
    "        \n",
    "        X, anchors[4], cls_preds[4], bbox_preds[4] = blk_forward(X, self.blk_4, sizes[4], ratios[4], self.cls_4, self.bbox_4)\n",
    "\n",
    "        return (torch.cat(anchors, dim=0), concat_preds(cls_preds).reshape((-1, 5444, self.num_classes + 1)), concat_preds(bbox_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9993e312",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors, cls_preds, bbox_preds = [None] * 5, [None] * 5, [None] * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b6f1b8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output anchors: torch.Size([5444, 4])\n",
      "output class preds: torch.Size([32, 5444, 2])\n",
      "output cbbox preds: torch.Size([32, 21776])\n"
     ]
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) ==  nn.Linear or type(m) == nn.Conv2d:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        \n",
    "net = TinySSD(3, num_classes = 1)\n",
    "net.apply(init_weights)\n",
    "\n",
    "X = torch.zeros((32, 3, 256, 256))\n",
    "anchors, cls_preds, bbox_preds = net(X)\n",
    "\n",
    "print('output anchors:', anchors.shape)\n",
    "print('output class preds:', cls_preds.shape)\n",
    "print('output cbbox preds:', bbox_preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e84481",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b8b411",
   "metadata": {},
   "source": [
    "### Data Reading and Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "903ff381",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2l.download_and_preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "11c2df97",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "data_dir = '../data/pikachu'\n",
    "train_dataset = d2l.PIKACHU(data_dir, 'train')\n",
    "val_dataset = d2l.PIKACHU(data_dir, 'val')\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle = True, num_workers = 4)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size = batch_size, shuffle = False, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "06e56b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "26b79f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = TinySSD(3, num_classes = 1)\n",
    "net.apply(init_weights)\n",
    "net = net.to(device)\n",
    "\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 5e-4\n",
    "optimizer = optim.SGD(net.parameters(), lr = learning_rate, weight_decay = weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9759953e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
